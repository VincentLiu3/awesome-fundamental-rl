# Fundamental Reinforcement Learning (In Progress)
A list of learning resources for fundamental reinforcement learning.

Books
---
* Reinforcement Learning: An Introduction. Rich Sutton and Andrew Barto. [[PDF]](http://www.incompleteideas.net/book/the-book-2nd.html)
* Algorithms for Reinforcement Learning. Csaba Szepesvari. [[PDF]](https://sites.ualberta.ca/~szepesva/RLBook.html)
* Reinforcement Learning: Theory and Algorithms. Alekh Agarwal, Nan Jiang, Sham Kakade. [[PDF]](https://rltheorybook.github.io/rl_monograph_AJK.pdf)
* Neuro-Dynamic Programming. Dimitri P. Bertsekas and John Tsitsiklis. 
* Markov Decision Processes: Discrete Stochastic Dynamic Programming. Martin Puterman.

Lecture Notes
---
* CS 598 Statistical Reinforcement Learning. Nan Jiang. [[link]](https://nanjiang.cs.illinois.edu/cs598/)
* Approximate Dynamic Programming. Ben Van Roy. [[link]](https://homes.cs.washington.edu/~todorov/courses/amath579/VanRoy_notes.pdf)
* Mathematical Techniques for Machine Learning. Prakash Panangaden. [[link]](https://www.cs.mcgill.ca/~prakash/Courses/599/comp599.html)

Papers
---
#### RL formulation
* Unifying Task Specification in Reinforcement Learning. Martha White. [[PDF]](http://proceedings.mlr.press/v70/white17a/white17a.pdf)  
* Rethinking the Discount Factor in Reinforcement Learning: A Decision Theoretic Approach. Silviu Pitis. [[PDF]](https://arxiv.org/pdf/1902.02893.pdf)

#### Objectives in RL
* Scherrer B. Should one compute the Temporal Difference fix point or minimize the Bellman Residual? The unified oblique projection view. [[PDF]](http://arxiv.org/abs/1011.4362)
* Schoknecht R. Optimality of Reinforcement Learning Algorithms with Linear Function Approximation. Advances in Neural Information Processing Systems. 2015 [[PDF]](http://papers.nips.cc/paper/2322-optimality-of-reinforcement-learning-algorithms-with-linear-function-approximation.pdf)

#### Approximate DP
* Scherrer B.  Approximate Policy Iteration Schemes: A Comparison. 
* Farahmand A, Szepesvári C, Munos R. Error Propagation for Approximate Policy and Value Iteration. Advances in Neural Information Processing Systems.
* Munos R, Szepesvari C. Finite-Time Bounds for Fitted Value Iteration. 2008.
* Munos R. Performance Bounds in $L_p$‐norm for Approximate Value Iteration. SIAM J Control Optim. 2007.
* Antos A, Szepesvari C, Munos R. Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path. 2006.
* Munos R. Error Bounds for Approximate Value Iteration. 2005
* Munos R. Error Bounds for Approximate Policy Iteration. 2003.
* Williams R, Baird LC. Tight Performance Bounds on Greedy Policies Based on Imperfect Value Functions. 1993.

#### Approximate LP
* A Linearly Relaxed Approximate Linear Program for Markov Decision Processes. [[PDF]](https://sites.ualberta.ca/~szepesva/papers/2018-lralp-ieee-tac.pdf)

#### Temporal Differences Learning
* Learning to predict by the methods of temporal differences. Rich Sutton. [[PDF]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.132.7760&rep=rep1&type=pdf)
* TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning. Artemij Amiranashvili, et al. [[PDF]](https://arxiv.org/pdf/1806.01175.pdf)

#### Convergence of RL algorithms
* Convergence of Stochastic Iterative Dynamic Programming Algorithms. [[PDF]](https://papers.nips.cc/paper/764-convergence-of-stochastic-iterative-dynamic-programming-algorithms.pdf)
* Q-Learning. Christopher Watkins and Peter Dayan. [[PDF]](http://www.gatsby.ucl.ac.uk/~dayan/papers/cjch.pdf)
* Reinforcement Learning with Function Approximation Converges to a Region. [[PDF]](https://pdfs.semanticscholar.org/6f36/fa118e757ce917b7a03664768787d8b9bb62.pdf)
* Chattering in SARSA. [[PDF]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.325&rep=rep1&type=pdf)

#### Sample Complexity of RL algorithms
* Learning with Good Feature Representations in Bandits and in RL with a Generative Model. Tor Lattimore and Csaba Szepesvari. [[PDF]](https://arxiv.org/pdf/1911.07676.pdf) 
* Is a good representation sufficient for sample efficient reinforcement learning. Simon Du, et al. [[PDF]](https://arxiv.org/abs/1910.03016) 

#### RL with Function Approximation
* Analysis of temporal-diffference learning with function approximation. John Tsitsiklis and Benjamin Van Roy. [[PDF]](http://www.mit.edu/~jnt/Papers/J063-97-bvr-td.pdf)
* An Analysis of Linear Models, Linear Value-Function Approximation, and Feature Selection for Reinforcement Learning. [[PDF]](https://users.cs.duke.edu/~parr/icml08.pdf)

#### Least-Squares Methods
* Least-Squares Methods in Reinforcement Learning for Control. Michail Lagoudakis, Ronald Parr, and Michael Littman. [[PDF]](https://users.cs.duke.edu/~parr/setn02.pdf)
* Linear Least-Squares Algorithms for Temporal Difference Learning. Steven Bradtke, and Andrew Barto. [[PDF]](https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1016&context=cs_faculty_pubs)

#### Deep Q-learning
* Towards Characterizing Divergence in Deep Q-Learning. Joshua Achiam, Ethan Knight, and Pieter Abbeel.
* Diagnosing Bottlenecks in Deep Q-learning Algorithms. Justin Fu, et al. 
* Deep Reinforcement Learning and the Deadly Triad. Hado van Hasselt, et al. [[PDF]](https://arxiv.org/pdf/1812.02648.pdf)
* A Theoretical Analysis of Deep Q-Learning. Zhuoran Yang, et al. [[PDF]](https://arxiv.org/pdf/1901.00137.pdf)

#### Math for ML
* A Tutorial on Fisher Information. Alexander Ly, et al. [[PDF]](https://arxiv.org/pdf/1705.01064.pdf)
